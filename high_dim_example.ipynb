{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:18:46<00:00,  4.73s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "np.random.seed(123)\n",
    "n_samples = 1000\n",
    "n_features = 100\n",
    "ipw_effects = []\n",
    "ra_effects = []\n",
    "dom_effects = []\n",
    "psm_effects = []\n",
    "dr_effects = []\n",
    "for iteration in tqdm(range(1000)):\n",
    "    # Generate synthetic high-dimensional covariate data\n",
    "    X = np.random.normal(0, 1, size=(n_samples, n_features))\n",
    "\n",
    "    # Simulate treatment assignment influenced by the first five covariates\n",
    "    logit = np.dot(X[:, :5], np.random.rand(5)) - 1  # Adjusted to simulate different probabilities\n",
    "    T = np.random.binomial(1, p=1 / (1 + np.exp(-logit)))\n",
    "\n",
    "    # Simulate the outcome where treatment has a hypothetical positive effect\n",
    "    Y = 10 + np.dot(X[:, :5], np.random.rand(5)) + 5 * T + np.random.normal(0, 1, size=n_samples)\n",
    "\n",
    "\n",
    "    from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "    from econml.dr import DRLearner\n",
    "\n",
    "    # Specify propensity score model\n",
    "    propensity_model = LogisticRegression()\n",
    "    # Specify outcome model\n",
    "    outcome_model = LinearRegression()\n",
    "    # Setup and fit the doubly robust estimator\n",
    "    dr_learner = DRLearner(model_propensity=propensity_model, model_regression=outcome_model, model_final=LinearRegression())\n",
    "    dr_learner.fit(Y, T, X=X)\n",
    "\n",
    "    # Estimate the causal effect\n",
    "    effects = dr_learner.effect(X)\n",
    "\n",
    "    # Estimating propensity scores\n",
    "    logit_ipw = LogisticRegression()\n",
    "    logit_ipw.fit(X, T)\n",
    "    pscores = logit_ipw.predict_proba(X)[:, 1]\n",
    "\n",
    "    # Calculating weights\n",
    "    weights = T / pscores + (1 - T) / (1 - pscores)\n",
    "\n",
    "    # Weighted regression for outcome\n",
    "    model_ipw = GradientBoostingRegressor()\n",
    "    model_ipw.fit(X, Y, sample_weight=weights)\n",
    "    predicted_ipw = model_ipw.predict(X)\n",
    "\n",
    "    # Estimating the effect\n",
    "    ipw_effect = np.mean(predicted_ipw[T == 1]) - np.mean(predicted_ipw[T == 0])\n",
    "\n",
    "    # Nearest neighbor matching\n",
    "    nn = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(X[T == 0])\n",
    "    _, indices = nn.kneighbors(X[T == 1])\n",
    "\n",
    "    # Calculate average effect on matched data\n",
    "    matched_controls = Y[T == 0][indices.flatten()]\n",
    "    matched_treated = Y[T == 1]\n",
    "    psm_effect = np.mean(matched_treated - matched_controls)\n",
    "\n",
    "    # Direct outcome model\n",
    "    model_dom = LinearRegression()\n",
    "    model_dom.fit(np.hstack((X, T.reshape(-1, 1))), Y)\n",
    "    predicted_dom = model_dom.predict(np.hstack((X, T.reshape(-1, 1))))\n",
    "\n",
    "    # Estimating the effect\n",
    "    dom_effect = np.mean(predicted_dom[T == 1]) - np.mean(predicted_dom[T == 0])\n",
    "\n",
    "    dr_effects.append(np.mean(effects))\n",
    "    ipw_effects.append(ipw_effect)\n",
    "    dom_effects.append(dom_effect)\n",
    "    psm_effects.append(psm_effect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4806640348239535\n",
      "Mean: 5.00 \n",
      "95% Confidence Interval (4.48, 5.52)\n",
      "3.2055144917062144\n",
      "Mean: 3.23 \n",
      "95% Confidence Interval (3.21, 3.25)\n",
      "5.929658452504605\n",
      "Mean: 5.95 \n",
      "95% Confidence Interval (5.93, 5.97)\n",
      "5.728815145871025\n",
      "Mean: 5.75 \n",
      "95% Confidence Interval (5.73, 5.77)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "for results in [dr_effects, ipw_effects, dom_effects, psm_effects]:\n",
    "    # Calculate mean and standard deviation\n",
    "    mean = np.mean(results)\n",
    "    std_dev = np.std(results)\n",
    "\n",
    "    # Calculate standard error\n",
    "    std_error = stats.sem(results)\n",
    "\n",
    "    # Calculate 95% confidence interval\n",
    "    ci = stats.t.interval(0.95, len(results) - 1, loc=mean, scale=std_error)\n",
    "    print(ci[0])\n",
    "    print(f\"Mean: {mean:.2f} \")\n",
    "    print(f\"95% Confidence Interval ({ci[0]:.2f}, {ci[1]:.2f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
